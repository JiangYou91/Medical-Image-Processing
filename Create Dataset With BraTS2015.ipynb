{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28c70feb870>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "import glob\n",
    "from medpy.io import load \n",
    "\n",
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"./brats2015/BRATS2015_Training/BRATS2015_Training/HGG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = glob.glob(dir_path + \"/*/*/*.mha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path_test = \"./brats2015/BRATS2015_Testing/Testing/HGG_LGG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = glob.glob(dir_path_test + \"/*/*/*.mha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./brats2015/BRATS2015_Testing/Testing/HGG_LGG\\\\brats_2013_pat0103_1\\\\VSD.Brain.XX.O.MR_Flair.54193\\\\VSD.Brain.XX.O.MR_Flair.54193.mha',\n",
       " './brats2015/BRATS2015_Testing/Testing/HGG_LGG\\\\brats_2013_pat0103_1\\\\VSD.Brain.XX.O.MR_T1.54194\\\\VSD.Brain.XX.O.MR_T1.54194.mha',\n",
       " './brats2015/BRATS2015_Testing/Testing/HGG_LGG\\\\brats_2013_pat0103_1\\\\VSD.Brain.XX.O.MR_T1c.54195\\\\VSD.Brain.XX.O.MR_T1c.54195.mha',\n",
       " './brats2015/BRATS2015_Testing/Testing/HGG_LGG\\\\brats_2013_pat0103_1\\\\VSD.Brain.XX.O.MR_T2.54196\\\\VSD.Brain.XX.O.MR_T2.54196.mha',\n",
       " './brats2015/BRATS2015_Testing/Testing/HGG_LGG\\\\brats_2013_pat0105_1\\\\VSD.Brain.XX.O.MR_Flair.54199\\\\VSD.Brain.XX.O.MR_Flair.54199.mha']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data, image_header = load(files_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240, 155)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset by selecting the MR image of type FLAIRE, T2, and OT Segementation. \n",
    "\n",
    "to reduce the dataset, select 60 images randomly in range [50, 110]. \n",
    "\n",
    "the deepth is noted in the file name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_T2 = [f for f in files_list if \"T2\" in f ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_OT = [f for f in files_list if \"OT\" in f ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_OT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_Flair = [f for f in files_list if \"Flair\" in f ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_Flair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the start and end range of selection\n",
    "start_idx, end_idx, step = 30, 120, 5\n",
    "\n",
    "#prefixed name of folders storing iamges\n",
    "prefixed_name_T2 = \"./BraTS2015_Medium/T2/HGG_\"\n",
    "\n",
    "prefixed_name_OT = \"./BraTS2015_Medium/OT/HGG_\"\n",
    "\n",
    "prefixed_name_OT_BACKGROUND = \"./BraTS2015_Medium/OT_BACKGROUND/HGG_\"\n",
    "\n",
    "prefixed_name_OT_BACKGROUND_test = \"./BraTS2015_Medium/OT_BACKGROUND/test/HGG_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "try:\n",
    "    os.makedirs(os.path.dirname('./BraTS2015_Medium/T2/'))\n",
    "except OSError as exc: # Guard against race condition\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "        \n",
    "try:\n",
    "    os.makedirs(os.path.dirname('./BraTS2015_Medium/OT/'))\n",
    "except OSError as exc: # Guard against race condition\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "        \n",
    "try:\n",
    "    os.makedirs(os.path.dirname('./BraTS2015_Medium/OT_BACKGROUND/'))\n",
    "except OSError as exc: # Guard against race condition\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale image and save it\n",
    "for i in range(len(files_T2)):\n",
    "    image_data, image_header = load(files_T2[i])\n",
    "    img_min, img_max = image_data.min(), image_data.max()\n",
    "    scaled_image_data = (image_data - img_min) / img_max\n",
    "    for j in range(start_idx, end_idx, step): \n",
    "        save_image(torch.tensor(scaled_image_data[:, :, j], dtype=torch.float32), prefixed_name_T2 + (\"%03d\" % i) + \"_\" + (\"%03d\" % j)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale image and save it\n",
    "for i in range(len(files_OT)):\n",
    "    image_data, image_header = load(files_OT[i])\n",
    "    img_min, img_max = image_data.min(), image_data.max()\n",
    "    scaled_image_data = (image_data - img_min) / img_max\n",
    "    for j in range(start_idx, end_idx, step): \n",
    "        save_image(torch.tensor(scaled_image_data[:, :, j], dtype=torch.float32), prefixed_name_OT + (\"%03d\" % i) + \"_\" + (\"%03d\" % j)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale image and save it ther version of OT with background \n",
    "for i in range(len(files_OT)):\n",
    "    \n",
    "    image_data_back, image_header_back = load(files_T2[i]) \n",
    "    img_min, img_max = image_data_back.min(), image_data_back.max()\n",
    "    scaled_image_data_back = (image_data_back - img_min) / img_max\n",
    "    scaled_image_data_back[scaled_image_data_back > 0] = 0.2\n",
    "    \n",
    "    image_data, image_header = load(files_OT[i])\n",
    "    img_min, img_max = image_data.min(), image_data.max()\n",
    "    scaled_image_data = (image_data - img_min) / img_max\n",
    "    scaled_image_data += scaled_image_data_back\n",
    "    \n",
    "    for j in range(start_idx, end_idx, step): \n",
    "        save_image(torch.tensor(scaled_image_data[:, :, j], dtype=torch.float32), prefixed_name_OT_BACKGROUND + (\"%03d\" % i) + \"_\" + (\"%03d\" % j)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
